{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST画像認識のtorch model ハイパーパラメータチューニング\n",
    "それでは，実際にMNISTの画像認識を通してハイパーパラメータのチューニングを行いたいと思います．\n",
    "\n",
    "### 実行環境???????\n",
    "- Python : 3.6.8\n",
    "- PyTorch : 0.4.1\n",
    "- Optuna : 0.12.0\n",
    "\n",
    "### チューニングを行うハイパーパラメータ\n",
    "- 畳み込み層の数（3 ~ 7）\n",
    "- 各畳み込み層のフィルタ数（16, 32, 48, ..., 128）\n",
    "- 全結合層のユニット数（100, 200, 300, 400, 500）\n",
    "- 活性化関数（ReLU, ELU）\n",
    "- 最適化手法（Adam, MomentumSGD, rmsprop）\n",
    "- 学習率（adam_lr(1e-10 ~ 1e-3), momentum_sgd_lr(1e-5 ~ 1e-1)）\n",
    "- weight_decay（1e-10 ~ 1e-3）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "CElpKgnAnF9k",
    "outputId": "426db975-c1f8-451a-c7fd-1f8705e8a981"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "BATCHSIZE = 128\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCHSIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCHSIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = tuple(np.linspace(0, 9, 10, dtype=np.uint8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iI8b6DEvnImr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import optuna\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "\n",
    "#モデルの定義\n",
    "\n",
    "#入力画像の高さと幅，畳み込み層のカーネルサイズ\n",
    "in_height = 28\n",
    "in_width = 28\n",
    "kernel = 3\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, trial, num_layer, mid_units, num_filters):\n",
    "    super(Net, self).__init__()\n",
    "    self.activation = get_activation(trial)\n",
    "    #第1層\n",
    "    self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=num_filters[0], kernel_size=3)])\n",
    "    self.out_height = in_height - kernel +1\n",
    "    self.out_width = in_width - kernel +1\n",
    "    #第2層以降\n",
    "    for i in range(1, num_layer):\n",
    "      self.convs.append(nn.Conv2d(in_channels=num_filters[i-1], out_channels=num_filters[i], kernel_size=3))\n",
    "      self.out_height = self.out_height - kernel + 1\n",
    "      self.out_width = self.out_width - kernel +1\n",
    "    #pooling層\n",
    "    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "    self.out_height = int(self.out_height / 2)\n",
    "    self.out_width = int(self.out_width / 2)\n",
    "    #線形層\n",
    "    self.out_feature = self.out_height * self.out_width * num_filters[num_layer - 1]\n",
    "    self.fc1 = nn.Linear(in_features=self.out_feature, out_features=mid_units) \n",
    "    self.fc2 = nn.Linear(in_features=mid_units, out_features=10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    for i, l in enumerate(self.convs):\n",
    "      x = l(x)\n",
    "      x = self.activation(x)\n",
    "    x = self.pool(x)\n",
    "    x = x.view(-1, self.out_feature)\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAa7nBc0nLPB"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return 1 - correct / len(test_loader.dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Optimaisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNWtzhLFnNVz"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def get_optimizer(trial, model):\n",
    "  optimizer_names = ['Adam', 'MomentumSGD', 'rmsprop']\n",
    "  optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n",
    "  \n",
    "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
    "  \n",
    "  if optimizer_name == optimizer_names[0]: \n",
    "    adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=adam_lr, weight_decay=weight_decay)\n",
    "  elif optimizer_name == optimizer_names[1]:\n",
    "    momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=momentum_sgd_lr, momentum=0.9, weight_decay=weight_decay)\n",
    "  else:\n",
    "    optimizer = optim.RMSprop(model.parameters())\n",
    "  \n",
    "  return optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune activate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRoTVTSinQIX"
   },
   "outputs": [],
   "source": [
    "def get_activation(trial):\n",
    "    activation_names = ['ReLU', 'ELU']\n",
    "    activation_name = trial.suggest_categorical('activation', activation_names)\n",
    "    \n",
    "    if activation_name == activation_names[0]:\n",
    "        activation = F.relu\n",
    "    else:\n",
    "        activation = F.elu\n",
    "    \n",
    "    return activation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the object function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06yJ1OOEnSIn"
   },
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "def objective(trial):\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  print(f'device == {device}')\n",
    "  \n",
    "  #畳み込み層の数\n",
    "  num_layer = trial.suggest_int('num_layer', 3, 7)\n",
    "  \n",
    "  #FC層のユニット数\n",
    "  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 500, 100))\n",
    "  \n",
    "  #各畳込み層のフィルタ数\n",
    "  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n",
    "  \n",
    "  model = Net(trial, num_layer, mid_units, num_filters).to(device)\n",
    "  optimizer = get_optimizer(trial, model)\n",
    "  \n",
    "  for step in range(EPOCH):\n",
    "    train(model, device, train_loader, optimizer)\n",
    "    error_rate = test(model, device, test_loader)\n",
    "    print(f'{step}fin | error rate {error_rate}')\n",
    "\n",
    "  print(f'{trial.number + 1} trial fin')\n",
    "  return error_rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmDi93T2nU_n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device == cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65890/2191877900.py:10: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 500, 100))\n",
      "/tmp/ipykernel_65890/2191877900.py:13: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n",
      "/tmp/ipykernel_65890/3394128390.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
      "/tmp/ipykernel_65890/3394128390.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0fin | error rate 0.08819999999999995\n",
      "1fin | error rate 0.05600000000000005\n",
      "2fin | error rate 0.037699999999999956\n",
      "3fin | error rate 0.02729999999999999\n",
      "4fin | error rate 0.02410000000000001\n",
      "5fin | error rate 0.020199999999999996\n",
      "6fin | error rate 0.01849999999999996\n",
      "7fin | error rate 0.01770000000000005\n",
      "8fin | error rate 0.016100000000000003\n",
      "9fin | error rate 0.017299999999999982\n",
      "1 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.036599999999999966\n",
      "1fin | error rate 0.029299999999999993\n",
      "2fin | error rate 0.024399999999999977\n",
      "3fin | error rate 0.023700000000000054\n",
      "4fin | error rate 0.019199999999999995\n",
      "5fin | error rate 0.024700000000000055\n",
      "6fin | error rate 0.02310000000000001\n",
      "7fin | error rate 0.023599999999999954\n",
      "8fin | error rate 0.028699999999999948\n",
      "9fin | error rate 0.026499999999999968\n",
      "2 trial fin\n",
      "device == cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65890/3394128390.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0fin | error rate 0.08589999999999998\n",
      "1fin | error rate 0.06730000000000003\n",
      "2fin | error rate 0.054200000000000026\n",
      "3fin | error rate 0.040000000000000036\n",
      "4fin | error rate 0.026699999999999946\n",
      "5fin | error rate 0.02070000000000005\n",
      "6fin | error rate 0.017900000000000027\n",
      "7fin | error rate 0.017199999999999993\n",
      "8fin | error rate 0.01859999999999995\n",
      "9fin | error rate 0.016100000000000003\n",
      "3 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.024399999999999977\n",
      "1fin | error rate 0.014399999999999968\n",
      "2fin | error rate 0.012700000000000045\n",
      "3fin | error rate 0.01319999999999999\n",
      "4fin | error rate 0.011099999999999999\n",
      "5fin | error rate 0.013499999999999956\n",
      "6fin | error rate 0.012299999999999978\n",
      "7fin | error rate 0.01200000000000001\n",
      "8fin | error rate 0.012499999999999956\n",
      "9fin | error rate 0.01319999999999999\n",
      "4 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.7583\n",
      "1fin | error rate 0.7958000000000001\n",
      "2fin | error rate 0.7368\n",
      "3fin | error rate 0.5684\n",
      "4fin | error rate 0.18169999999999997\n",
      "5fin | error rate 0.13139999999999996\n",
      "6fin | error rate 0.11619999999999997\n",
      "7fin | error rate 0.10670000000000002\n",
      "8fin | error rate 0.09989999999999999\n",
      "9fin | error rate 0.09730000000000005\n",
      "5 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.9045\n",
      "1fin | error rate 0.9016\n",
      "2fin | error rate 0.8972\n",
      "3fin | error rate 0.9108\n",
      "4fin | error rate 0.9026\n",
      "5fin | error rate 0.8972\n",
      "6fin | error rate 0.9108\n",
      "7fin | error rate 0.8991\n",
      "8fin | error rate 0.9108\n",
      "9fin | error rate 0.9018\n",
      "6 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.04820000000000002\n",
      "1fin | error rate 0.030399999999999983\n",
      "2fin | error rate 0.034399999999999986\n",
      "3fin | error rate 0.027800000000000047\n",
      "4fin | error rate 0.01970000000000005\n",
      "5fin | error rate 0.019299999999999984\n",
      "6fin | error rate 0.027100000000000013\n",
      "7fin | error rate 0.9108\n",
      "8fin | error rate 0.9042\n",
      "9fin | error rate 0.9026\n",
      "7 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.8991\n",
      "1fin | error rate 0.8972\n",
      "2fin | error rate 0.9042\n",
      "3fin | error rate 0.9042\n",
      "4fin | error rate 0.8968\n",
      "5fin | error rate 0.9042\n",
      "6fin | error rate 0.8865\n",
      "7fin | error rate 0.8865\n",
      "8fin | error rate 0.8968\n",
      "9fin | error rate 0.9018\n",
      "8 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.09189999999999998\n",
      "1fin | error rate 0.06879999999999997\n",
      "2fin | error rate 0.05120000000000002\n",
      "3fin | error rate 0.032299999999999995\n",
      "4fin | error rate 0.036900000000000044\n",
      "5fin | error rate 0.029100000000000015\n",
      "6fin | error rate 0.022800000000000042\n",
      "7fin | error rate 0.0252\n",
      "8fin | error rate 0.02939999999999998\n",
      "9fin | error rate 0.03939999999999999\n",
      "9 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.022199999999999998\n",
      "1fin | error rate 0.023700000000000054\n",
      "2fin | error rate 0.019299999999999984\n",
      "3fin | error rate 0.02210000000000001\n",
      "4fin | error rate 0.01849999999999996\n",
      "5fin | error rate 0.01880000000000004\n",
      "6fin | error rate 0.01200000000000001\n",
      "7fin | error rate 0.017800000000000038\n",
      "8fin | error rate 0.015000000000000013\n",
      "9fin | error rate 0.015499999999999958\n",
      "10 trial fin\n"
     ]
    }
   ],
   "source": [
    "TRIAL_SIZE = 1\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "jAEVew7PnXCa",
    "outputId": "ba19b6a1-852e-4bf6-a8c7-afd6c62ff934"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layer': 6,\n",
       " 'mid_units': 400.0,\n",
       " 'num_filter_0': 128.0,\n",
       " 'num_filter_1': 112.0,\n",
       " 'num_filter_2': 128.0,\n",
       " 'num_filter_3': 32.0,\n",
       " 'num_filter_4': 64.0,\n",
       " 'num_filter_5': 16.0,\n",
       " 'activation': 'ELU',\n",
       " 'optimizer': 'MomentumSGD',\n",
       " 'weight_decay': 3.705858691297322e-09,\n",
       " 'momentum_sgd_lr': 0.014335285805707738}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "01556tDFncfh",
    "outputId": "b681028b-47fb-4c8c-bbe3-d561047ea007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01319999999999999\n"
     ]
    }
   ],
   "source": [
    "print(study.best_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# チューニングを行わなかった場合との比較\n",
    "チューニングを行わなかった場合のハイパーパラメータの値は以下のように指定．\n",
    "\n",
    "- 畳み込み層の数 : 3\n",
    "- 各畳み込み層のフィルタ数 : 16, 32, 48\n",
    "- 全結合層のユニット数 : 100\n",
    "- 活性化関数 : ReLU\n",
    "- 最適化手法 : Adam\n",
    "- 学習率 : 0.001\n",
    "- weight_decay : 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Optuna_with_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
