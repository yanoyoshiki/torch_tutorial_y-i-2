{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST画像認識のtorch model ハイパーパラメータチューニング\n",
    "\n",
    "\n",
    "### チューニングを行うハイパーパラメータ\n",
    "- 畳み込み層の数\n",
    "- 各畳み込み層のフィルタ数\n",
    "- 全結合層のユニット数\n",
    "- 活性化関数\n",
    "- 最適化手法\n",
    "- 学習率\n",
    "- weight_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータチューニングを楽にする方法\n",
    "上のハイパラをチューニングすることで良い性能が得られる可能性がある.\n",
    "しかしハイパラメータのチューニングはネットワークの性質と元データやタスクに関する情報から推測されるものであり、自動化を行わなければ複数結果を比較して最善と思われるものを自身で決定しなければならない. \n",
    "その個人的な意志力が介在するのはデータ分析的には好ましくないために自動化する必要がある．\n",
    "そこで今回はOptunaを採用し、パイパラチューニングを効率的に行う．\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "CElpKgnAnF9k",
    "outputId": "426db975-c1f8-451a-c7fd-1f8705e8a981"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 20:31:38.966417: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-14 20:31:38.991759: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 20:31:39.456511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from optuna.integration.tensorboard import TensorBoardCallback\n",
    "import optuna\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "\n",
    "#set seeds\n",
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "\n",
    "torch_fix_seed()\n",
    "\n",
    "\n",
    "BATCHSIZE = 128\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCHSIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCHSIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = tuple(np.linspace(0, 9, 10, dtype=np.uint8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iI8b6DEvnImr"
   },
   "outputs": [],
   "source": [
    "#モデルの定義\n",
    "\n",
    "#入力画像の高さと幅，畳み込み層のカーネルサイズ\n",
    "in_height = 28\n",
    "in_width = 28\n",
    "kernel = 3\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, trial, num_layer, mid_units, num_filters):\n",
    "    super(Net, self).__init__()\n",
    "    self.activation = get_activation(trial)\n",
    "    #第1層\n",
    "    self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=num_filters[0], kernel_size=3)])\n",
    "    self.out_height = in_height - kernel +1\n",
    "    self.out_width = in_width - kernel +1\n",
    "    #第2層以降\n",
    "    for i in range(1, num_layer):\n",
    "      self.convs.append(nn.Conv2d(in_channels=num_filters[i-1], out_channels=num_filters[i], kernel_size=3))\n",
    "      self.out_height = self.out_height - kernel + 1\n",
    "      self.out_width = self.out_width - kernel +1\n",
    "    #pooling層\n",
    "    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "    self.out_height = int(self.out_height / 2)\n",
    "    self.out_width = int(self.out_width / 2)\n",
    "    #線形層\n",
    "    self.out_feature = self.out_height * self.out_width * num_filters[num_layer - 1]\n",
    "    self.fc1 = nn.Linear(in_features=self.out_feature, out_features=mid_units) \n",
    "    self.fc2 = nn.Linear(in_features=mid_units, out_features=10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    for i, l in enumerate(self.convs):\n",
    "      x = l(x)\n",
    "      x = self.activation(x)\n",
    "    x = self.pool(x)\n",
    "    x = x.view(-1, self.out_feature)\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAa7nBc0nLPB"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return 1 - correct / len(test_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Optimaisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNWtzhLFnNVz"
   },
   "outputs": [],
   "source": [
    "def get_optimizer(trial, model):\n",
    "  optimizer_names = ['Adam', 'MomentumSGD', 'rmsprop']\n",
    "  optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n",
    "  \n",
    "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
    "  \n",
    "  if optimizer_name == optimizer_names[0]: \n",
    "    adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=adam_lr, weight_decay=weight_decay)\n",
    "  elif optimizer_name == optimizer_names[1]:\n",
    "    momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=momentum_sgd_lr, momentum=0.9, weight_decay=weight_decay)\n",
    "  else:\n",
    "    optimizer = optim.RMSprop(model.parameters())\n",
    "  \n",
    "  return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune activate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRoTVTSinQIX"
   },
   "outputs": [],
   "source": [
    "def get_activation(trial):\n",
    "    activation_names = ['ReLU', 'ELU']\n",
    "    activation_name = trial.suggest_categorical('activation', activation_names)\n",
    "    \n",
    "    if activation_name == activation_names[0]:\n",
    "        activation = F.relu\n",
    "    else:\n",
    "        activation = F.elu\n",
    "    \n",
    "    return activation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the object function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06yJ1OOEnSIn"
   },
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "def objective(trial):\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  print(f'device == {device}')\n",
    "  \n",
    "  #畳み込み層の数\n",
    "  num_layer = trial.suggest_int('num_layer', 3, 7)\n",
    "  \n",
    "  #FC層のユニット数\n",
    "  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 500, 100))\n",
    "  \n",
    "  #各畳込み層のフィルタ数\n",
    "  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n",
    "  \n",
    "  model = Net(trial, num_layer, mid_units, num_filters).to(device)\n",
    "  optimizer = get_optimizer(trial, model)\n",
    "  \n",
    "  for step in range(EPOCH):\n",
    "    train(model, device, train_loader, optimizer)\n",
    "    error_rate = test(model, device, test_loader)\n",
    "    print(f'{step}fin | error rate {error_rate}')\n",
    "\n",
    "  print(f'{trial.number + 1} trial fin')\n",
    "  return error_rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmDi93T2nU_n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12526/56581319.py:4: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "  tensorboard_callback = TensorBoardCallback(f\"logs/MNIST/{datetime.datetime.now()}/Optuna/\", metric_name=\"error_rate\")\n",
      "/tmp/ipykernel_12526/3690163298.py:10: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 500, 100))\n",
      "/tmp/ipykernel_12526/3690163298.py:13: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device == cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12526/2611439263.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0fin | error rate 0.8872\n",
      "1fin | error rate 0.8846\n",
      "2fin | error rate 0.8863\n",
      "3fin | error rate 0.8991\n",
      "4fin | error rate 0.9108\n"
     ]
    }
   ],
   "source": [
    "from optuna.integration.tensorboard import TensorBoardCallback\n",
    "\n",
    "TRIAL_SIZE = 50\n",
    "tensorboard_callback = TensorBoardCallback(f\"logs/MNIST/{datetime.datetime.now()}/Optuna/\", metric_name=\"error_rate\")\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=TRIAL_SIZE, callbacks=[tensorboard_callback])\n",
    "# ipdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このOptunaを用いたパラメータ探索に関しては ./Optuna_MNIST.py で実装を行ったそのため以下のコマンドを実行すると学習およびパラメータ探索が開始される．\n",
    "結果はtensorbord上で確認できるため\n",
    "以下のコマンドを実行する必要がある\n",
    "```\n",
    "tensorboard --logdir /root/src/logs/MNIST/<実行した日時>/Optuna --host 0.0.0.0 --port 6006\n",
    "```\n",
    "そしてtensorboardの起動を確認後、左上のタブにおいてHPARAMSという欄がある.この欄を選択すると画面が切り替わる. その後, 画面中央のPARALLEL COORDINATES VIEWを選択することで下記の画像を確認できる. \n",
    "このグラフは各ハイパラメータと結果の関係をグラフ化したもので，このグラフから各ハイパラメータがどのように結果に対して寄与しているのかを確認できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img=Image.open(\"MNIST.png\")\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の写真からわかることは各パラーメータ値とそのパラメータ設定で推論を行った時の精度である．\n",
    "errorrateと他パラメータの関係として以下のことが挙げられる\n",
    "\n",
    "- 最適化手法(optimizer)は、今回の探索結果において、\"MomentumSGD\"と\"Adam\"が多数採用され、エラー率が低くなった． \n",
    "- フィルター数は、5-7が採用されており、畳み込み層は比較的多い方が精度が良くなることがわかった．\n",
    "- 全結合層のユニット数は、100-500が採用されているが、500を超えると精度が急激に悪くなることから、400より下回ること好ましいと言え、最適パラメータとしては、100以下であることも考えらえる．\n",
    "\n",
    "以上のことから、今回の最適パラメータ選択において特徴的な点は以下のことが言える．\n",
    "- 最適化手法: \"MomentumSGD\"と\"Adam\"\n",
    "- 畳み込み層の数: 6\n",
    "- 全結合層のユニット数:400以下\n",
    "\n",
    "\n",
    "Optunaには最適パラメータを保持する機能があり，その保持パラーメータとそのハイパラで組まれたネットワークのerror rateが出力できる．\n",
    "この結果より発見されたパラメータは\n",
    "\n",
    "{'num_layer': 6, 'mid_units': 400.0, 'num_filter_0': 128.0, 'num_filter_1': 112.0, 'num_filter_2': 128.0, 'num_filter_3': 32.0, 'num_filter_4': 64.0, 'num_filter_5': 16.0, 'activation': 'ELU', 'optimizer': 'MomentumSGD', 'weight_decay': 3.705858691297322e-09, 'momentum_sgd_lr': 0.014335285805707738}\n",
    "\n",
    "\n",
    "であり，そのネットワークでのerror rateは 0.015100\n",
    "\n",
    "\n",
    "以下のように、調整前よりも性能が上がっていることが確認できる．\n",
    "\n",
    "\n",
    "【最適なパラメータ調整を行なった実行】\n",
    "\n",
    "0fin | error rate 0.022800000000000042\n",
    "\n",
    "1fin | error rate 0.017100000000000004\n",
    "\n",
    "2fin | error rate 0.011700000000000044\n",
    "\n",
    "3fin | error rate 0.01429999999999998\n",
    "\n",
    "4fin | error rate 0.011600000000000055\n",
    "\n",
    "5fin | error rate 0.011399999999999966\n",
    "\n",
    "6fin | error rate 0.010099999999999998\n",
    "\n",
    "7fin | error rate 0.010499999999999954\n",
    "\n",
    "8fin | error rate 0.00990000000000002\n",
    "\n",
    "9fin | error rate 0.011099999999999999\n",
    "\n",
    "\n",
    "【不適切なパラメータ調整を行った実行】\n",
    "\n",
    "0fin | error rate 0.022700000000000053\n",
    "\n",
    "1fin | error rate 0.014599999999999946\n",
    "\n",
    "2fin | error rate 0.015499999999999958\n",
    "\n",
    "3fin | error rate 0.013900000000000023\n",
    "\n",
    "4fin | error rate 0.01419999999999999\n",
    "\n",
    "5fin | error rate 0.0131\n",
    "\n",
    "6fin | error rate 0.012499999999999956\n",
    "\n",
    "7fin | error rate 0.011800000000000033\n",
    "\n",
    "8fin | error rate 0.011800000000000033\n",
    "\n",
    "9fin | error rate 0.013599999999999945\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Optuna_with_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
