{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST画像認識のtorch model ハイパーパラメータチューニング\n",
    "それでは，実際にMNISTの画像認識を通してハイパーパラメータのチューニングを行いたいと思います．\n",
    "\n",
    "### 実行環境???????\n",
    "- \n",
    "\n",
    "### チューニングを行うハイパーパラメータ\n",
    "- 畳み込み層の数（3 ~ 7）\n",
    "- 各畳み込み層のフィルタ数（16, 32, 48, ..., 128）\n",
    "- 全結合層のユニット数（100, 200, 300, 400, 500）\n",
    "- 活性化関数（ReLU, ELU）\n",
    "- 最適化手法（Adam, MomentumSGD, rmsprop）\n",
    "- 学習率（adam_lr(1e-10 ~ 1e-3), momentum_sgd_lr(1e-5 ~ 1e-1)）\n",
    "- weight_decay（1e-10 ~ 1e-3）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータチューニングを楽にする方法\n",
    "上のハイパラをチューニングすることで良い性能が得られる可能性がある.\n",
    "しかしハイパラメータのチューニングはネットワークの性質と元データやタスクに関する情報から推測されるものであり、自動化を行わなければ複数結果を比較して最善と思われるものを自身で決定しなければならない. \n",
    "その個人的な意志力が介在するのはデータ分析的には好ましくないために自動化する必要がある．\n",
    "そこで今回はOptunaを採用し、パイパラチューニングを効率的に行う．\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "CElpKgnAnF9k",
    "outputId": "426db975-c1f8-451a-c7fd-1f8705e8a981"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import ipdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from optuna.integration.tensorboard import TensorBoardCallback\n",
    "import optuna\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "\n",
    "#set seeds\n",
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "\n",
    "torch_fix_seed()\n",
    "\n",
    "\n",
    "BATCHSIZE = 128\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCHSIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCHSIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = tuple(np.linspace(0, 9, 10, dtype=np.uint8))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iI8b6DEvnImr"
   },
   "outputs": [],
   "source": [
    "#モデルの定義\n",
    "\n",
    "#入力画像の高さと幅，畳み込み層のカーネルサイズ\n",
    "in_height = 28\n",
    "in_width = 28\n",
    "kernel = 3\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, trial, num_layer, mid_units, num_filters):\n",
    "    super(Net, self).__init__()\n",
    "    self.activation = get_activation(trial)\n",
    "    #第1層\n",
    "    self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=num_filters[0], kernel_size=3)])\n",
    "    self.out_height = in_height - kernel +1\n",
    "    self.out_width = in_width - kernel +1\n",
    "    #第2層以降\n",
    "    for i in range(1, num_layer):\n",
    "      self.convs.append(nn.Conv2d(in_channels=num_filters[i-1], out_channels=num_filters[i], kernel_size=3))\n",
    "      self.out_height = self.out_height - kernel + 1\n",
    "      self.out_width = self.out_width - kernel +1\n",
    "    #pooling層\n",
    "    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "    self.out_height = int(self.out_height / 2)\n",
    "    self.out_width = int(self.out_width / 2)\n",
    "    #線形層\n",
    "    self.out_feature = self.out_height * self.out_width * num_filters[num_layer - 1]\n",
    "    self.fc1 = nn.Linear(in_features=self.out_feature, out_features=mid_units) \n",
    "    self.fc2 = nn.Linear(in_features=mid_units, out_features=10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    for i, l in enumerate(self.convs):\n",
    "      x = l(x)\n",
    "      x = self.activation(x)\n",
    "    x = self.pool(x)\n",
    "    x = x.view(-1, self.out_feature)\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAa7nBc0nLPB"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return 1 - correct / len(test_loader.dataset)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Optimaisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNWtzhLFnNVz"
   },
   "outputs": [],
   "source": [
    "def get_optimizer(trial, model):\n",
    "  optimizer_names = ['Adam', 'MomentumSGD', 'rmsprop']\n",
    "  optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n",
    "  \n",
    "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
    "  \n",
    "  if optimizer_name == optimizer_names[0]: \n",
    "    adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=adam_lr, weight_decay=weight_decay)\n",
    "  elif optimizer_name == optimizer_names[1]:\n",
    "    momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=momentum_sgd_lr, momentum=0.9, weight_decay=weight_decay)\n",
    "  else:\n",
    "    optimizer = optim.RMSprop(model.parameters())\n",
    "  \n",
    "  return optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune activate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRoTVTSinQIX"
   },
   "outputs": [],
   "source": [
    "def get_activation(trial):\n",
    "    activation_names = ['ReLU', 'ELU']\n",
    "    activation_name = trial.suggest_categorical('activation', activation_names)\n",
    "    \n",
    "    if activation_name == activation_names[0]:\n",
    "        activation = F.relu\n",
    "    else:\n",
    "        activation = F.elu\n",
    "    \n",
    "    return activation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the object function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06yJ1OOEnSIn"
   },
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "def objective(trial):\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  print(f'device == {device}')\n",
    "  \n",
    "  #畳み込み層の数\n",
    "  num_layer = trial.suggest_int('num_layer', 3, 7)\n",
    "  \n",
    "  #FC層のユニット数\n",
    "  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 500, 100))\n",
    "  \n",
    "  #各畳込み層のフィルタ数\n",
    "  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n",
    "  \n",
    "  model = Net(trial, num_layer, mid_units, num_filters).to(device)\n",
    "  optimizer = get_optimizer(trial, model)\n",
    "  \n",
    "  for step in range(EPOCH):\n",
    "    train(model, device, train_loader, optimizer)\n",
    "    error_rate = test(model, device, test_loader)\n",
    "    print(f'{step}fin | error rate {error_rate}')\n",
    "\n",
    "  print(f'{trial.number + 1} trial fin')\n",
    "  return error_rate\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmDi93T2nU_n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device == cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65890/2191877900.py:10: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 500, 100))\n",
      "/tmp/ipykernel_65890/2191877900.py:13: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n",
      "/tmp/ipykernel_65890/3394128390.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
      "/tmp/ipykernel_65890/3394128390.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0fin | error rate 0.08819999999999995\n",
      "1fin | error rate 0.05600000000000005\n",
      "2fin | error rate 0.037699999999999956\n",
      "3fin | error rate 0.02729999999999999\n",
      "4fin | error rate 0.02410000000000001\n",
      "5fin | error rate 0.020199999999999996\n",
      "6fin | error rate 0.01849999999999996\n",
      "7fin | error rate 0.01770000000000005\n",
      "8fin | error rate 0.016100000000000003\n",
      "9fin | error rate 0.017299999999999982\n",
      "1 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.036599999999999966\n",
      "1fin | error rate 0.029299999999999993\n",
      "2fin | error rate 0.024399999999999977\n",
      "3fin | error rate 0.023700000000000054\n",
      "4fin | error rate 0.019199999999999995\n",
      "5fin | error rate 0.024700000000000055\n",
      "6fin | error rate 0.02310000000000001\n",
      "7fin | error rate 0.023599999999999954\n",
      "8fin | error rate 0.028699999999999948\n",
      "9fin | error rate 0.026499999999999968\n",
      "2 trial fin\n",
      "device == cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65890/3394128390.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0fin | error rate 0.08589999999999998\n",
      "1fin | error rate 0.06730000000000003\n",
      "2fin | error rate 0.054200000000000026\n",
      "3fin | error rate 0.040000000000000036\n",
      "4fin | error rate 0.026699999999999946\n",
      "5fin | error rate 0.02070000000000005\n",
      "6fin | error rate 0.017900000000000027\n",
      "7fin | error rate 0.017199999999999993\n",
      "8fin | error rate 0.01859999999999995\n",
      "9fin | error rate 0.016100000000000003\n",
      "3 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.024399999999999977\n",
      "1fin | error rate 0.014399999999999968\n",
      "2fin | error rate 0.012700000000000045\n",
      "3fin | error rate 0.01319999999999999\n",
      "4fin | error rate 0.011099999999999999\n",
      "5fin | error rate 0.013499999999999956\n",
      "6fin | error rate 0.012299999999999978\n",
      "7fin | error rate 0.01200000000000001\n",
      "8fin | error rate 0.012499999999999956\n",
      "9fin | error rate 0.01319999999999999\n",
      "4 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.7583\n",
      "1fin | error rate 0.7958000000000001\n",
      "2fin | error rate 0.7368\n",
      "3fin | error rate 0.5684\n",
      "4fin | error rate 0.18169999999999997\n",
      "5fin | error rate 0.13139999999999996\n",
      "6fin | error rate 0.11619999999999997\n",
      "7fin | error rate 0.10670000000000002\n",
      "8fin | error rate 0.09989999999999999\n",
      "9fin | error rate 0.09730000000000005\n",
      "5 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.9045\n",
      "1fin | error rate 0.9016\n",
      "2fin | error rate 0.8972\n",
      "3fin | error rate 0.9108\n",
      "4fin | error rate 0.9026\n",
      "5fin | error rate 0.8972\n",
      "6fin | error rate 0.9108\n",
      "7fin | error rate 0.8991\n",
      "8fin | error rate 0.9108\n",
      "9fin | error rate 0.9018\n",
      "6 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.04820000000000002\n",
      "1fin | error rate 0.030399999999999983\n",
      "2fin | error rate 0.034399999999999986\n",
      "3fin | error rate 0.027800000000000047\n",
      "4fin | error rate 0.01970000000000005\n",
      "5fin | error rate 0.019299999999999984\n",
      "6fin | error rate 0.027100000000000013\n",
      "7fin | error rate 0.9108\n",
      "8fin | error rate 0.9042\n",
      "9fin | error rate 0.9026\n",
      "7 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.8991\n",
      "1fin | error rate 0.8972\n",
      "2fin | error rate 0.9042\n",
      "3fin | error rate 0.9042\n",
      "4fin | error rate 0.8968\n",
      "5fin | error rate 0.9042\n",
      "6fin | error rate 0.8865\n",
      "7fin | error rate 0.8865\n",
      "8fin | error rate 0.8968\n",
      "9fin | error rate 0.9018\n",
      "8 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.09189999999999998\n",
      "1fin | error rate 0.06879999999999997\n",
      "2fin | error rate 0.05120000000000002\n",
      "3fin | error rate 0.032299999999999995\n",
      "4fin | error rate 0.036900000000000044\n",
      "5fin | error rate 0.029100000000000015\n",
      "6fin | error rate 0.022800000000000042\n",
      "7fin | error rate 0.0252\n",
      "8fin | error rate 0.02939999999999998\n",
      "9fin | error rate 0.03939999999999999\n",
      "9 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.022199999999999998\n",
      "1fin | error rate 0.023700000000000054\n",
      "2fin | error rate 0.019299999999999984\n",
      "3fin | error rate 0.02210000000000001\n",
      "4fin | error rate 0.01849999999999996\n",
      "5fin | error rate 0.01880000000000004\n",
      "6fin | error rate 0.01200000000000001\n",
      "7fin | error rate 0.017800000000000038\n",
      "8fin | error rate 0.015000000000000013\n",
      "9fin | error rate 0.015499999999999958\n",
      "10 trial fin\n"
     ]
    }
   ],
   "source": [
    "from optuna.integration.tensorboard import TensorBoardCallback\n",
    "\n",
    "TRIAL_SIZE = 10\n",
    "tensorboard_callback = TensorBoardCallback(f\"logs/MNIST/{datetime.datetime.now()}/Optuna/\", metric_name=\"error_rate\")\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=TRIAL_SIZE, callbacks=[tensorboard_callback])\n",
    "# ipdb.set_trace()\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このOptunaを用いたパラメータ探索に関しては ./Optuna_MNIST.py で実装を行ったそのため以下のコマンドを実行すると学習およびパラメータ探索が開始される．\n",
    "結果はtensorbord上で確認できるため\n",
    "以下のコマンドを実行する必要がある\n",
    "```\n",
    "tensorboard --logdir /root/src/logs/MNIST/<実行した時刻>/Optuna --host 0.0.0.0 --port 6006\n",
    "```\n",
    "そしてtensorboardの起動を確認後、左上のタブにおいてHPARAMSという欄がある.この欄を選択すると画面が切り替わる. その後, 画面中央のPARALLEL COORDINATES VIEWを選択することで下記の画像を確認できる. \n",
    "このグラフは各ハイパラメータと結果の関係をグラフ化したもので，このグラフから各ハイパラメータがどのように結果に対して寄与しているのかを確認できる"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##写真を挿入"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の写真からわかることは各パラーメータ値とそのパラメータ設定で推論を行った時の精度である．\n",
    "errorrateと他パラメータの関係として以下のことが挙げられる\n",
    "\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "以上のことから_________________________ということが言える．\n",
    "\n",
    "\n",
    "Optunaには最適パラメータを保持する機能があり，その保持パラーメータとそのハイパラで組まれたネットワークのerror rateが出力できる．\n",
    "この結果より発見されたパラメータは\n",
    "ーーー\n",
    "であり，そのネットワークでのerror rateはーーー\n",
    "\n",
    "\n",
    "調整前よりも性能が上がっていることが確認できる．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コード全文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 19:07:57.941408: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-11 19:07:57.967528: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-11 19:07:58.510304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_88979/3379984770.py:164: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "  tensorboard_callback = TensorBoardCallback(f\"logs/MNIST/{datetime.datetime.now()}/Optuna/\", metric_name=\"error_rate\")\n",
      "/tmp/ipykernel_88979/3379984770.py:146: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 500, 100))\n",
      "/tmp/ipykernel_88979/3379984770.py:149: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n",
      "  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device == cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88979/3379984770.py:113: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
      "/tmp/ipykernel_88979/3379984770.py:119: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0fin | error rate 0.03180000000000005\n",
      "1fin | error rate 0.02090000000000003\n",
      "2fin | error rate 0.027599999999999958\n",
      "3fin | error rate 0.014900000000000024\n",
      "4fin | error rate 0.014900000000000024\n",
      "5fin | error rate 0.014100000000000001\n",
      "6fin | error rate 0.013000000000000012\n",
      "7fin | error rate 0.013299999999999979\n",
      "8fin | error rate 0.012499999999999956\n",
      "9fin | error rate 0.0131\n",
      "1 trial fin\n",
      "device == cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 19:09:28.473729: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 19:09:28.474248: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 19:09:28.474317: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 19:09:28.474993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 19:09:28.475069: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 19:09:28.475129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 19:09:28.475259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 19:09:28.475326: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 19:09:28.475386: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 19:09:28.475438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6105 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/tmp/ipykernel_88979/3379984770.py:116: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0fin | error rate 0.08660000000000001\n",
      "1fin | error rate 0.07169999999999999\n",
      "2fin | error rate 0.05489999999999995\n",
      "3fin | error rate 0.03939999999999999\n",
      "4fin | error rate 0.03269999999999995\n",
      "5fin | error rate 0.02739999999999998\n",
      "6fin | error rate 0.026100000000000012\n",
      "7fin | error rate 0.02300000000000002\n",
      "8fin | error rate 0.020399999999999974\n",
      "9fin | error rate 0.01870000000000005\n",
      "2 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.899\n",
      "1fin | error rate 0.899\n",
      "2fin | error rate 0.8865\n",
      "3fin | error rate 0.8865\n",
      "4fin | error rate 0.8865\n",
      "5fin | error rate 0.8865\n",
      "6fin | error rate 0.8865\n",
      "7fin | error rate 0.899\n",
      "8fin | error rate 0.8865\n",
      "9fin | error rate 0.8865\n",
      "3 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.9108\n",
      "1fin | error rate 0.9108\n",
      "2fin | error rate 0.9117\n",
      "3fin | error rate 0.906\n",
      "4fin | error rate 0.8976999999999999\n",
      "5fin | error rate 0.9028\n",
      "6fin | error rate 0.9026\n",
      "7fin | error rate 0.9026\n",
      "8fin | error rate 0.9026\n",
      "9fin | error rate 0.9026\n",
      "4 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.8972\n",
      "1fin | error rate 0.8968\n",
      "2fin | error rate 0.8968\n",
      "3fin | error rate 0.8865\n",
      "4fin | error rate 0.9026\n",
      "5fin | error rate 0.8972\n",
      "6fin | error rate 0.899\n",
      "7fin | error rate 0.9042\n",
      "8fin | error rate 0.8972\n",
      "9fin | error rate 0.9108\n",
      "5 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.8972\n",
      "1fin | error rate 0.8972\n",
      "2fin | error rate 0.8972\n",
      "3fin | error rate 0.8972\n",
      "4fin | error rate 0.8865\n",
      "5fin | error rate 0.8865\n",
      "6fin | error rate 0.8865\n",
      "7fin | error rate 0.8865\n",
      "8fin | error rate 0.8865\n",
      "9fin | error rate 0.8641\n",
      "6 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.0232\n",
      "1fin | error rate 0.016900000000000026\n",
      "2fin | error rate 0.023299999999999987\n",
      "3fin | error rate 0.018399999999999972\n",
      "4fin | error rate 0.01770000000000005\n",
      "5fin | error rate 0.017100000000000004\n",
      "6fin | error rate 0.024599999999999955\n",
      "7fin | error rate 0.017800000000000038\n",
      "8fin | error rate 0.025000000000000022\n",
      "9fin | error rate 0.016100000000000003\n",
      "7 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.902\n",
      "1fin | error rate 0.8968\n",
      "2fin | error rate 0.8991\n",
      "3fin | error rate 0.8991\n",
      "4fin | error rate 0.899\n",
      "5fin | error rate 0.8865\n",
      "6fin | error rate 0.902\n",
      "7fin | error rate 0.8972\n",
      "8fin | error rate 0.899\n",
      "9fin | error rate 0.899\n",
      "8 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.022199999999999998\n",
      "1fin | error rate 0.020499999999999963\n",
      "2fin | error rate 0.018000000000000016\n",
      "3fin | error rate 0.014499999999999957\n",
      "4fin | error rate 0.01419999999999999\n",
      "5fin | error rate 0.01849999999999996\n",
      "6fin | error rate 0.01649999999999996\n",
      "7fin | error rate 0.015199999999999991\n",
      "8fin | error rate 0.01529999999999998\n",
      "9fin | error rate 0.013499999999999956\n",
      "9 trial fin\n",
      "device == cuda\n",
      "0fin | error rate 0.8039000000000001\n",
      "1fin | error rate 0.8469\n",
      "2fin | error rate 0.7174\n",
      "3fin | error rate 0.17930000000000001\n",
      "4fin | error rate 0.13239999999999996\n",
      "5fin | error rate 0.12209999999999999\n",
      "6fin | error rate 0.1179\n",
      "7fin | error rate 0.11019999999999996\n",
      "8fin | error rate 0.10899999999999999\n",
      "9fin | error rate 0.10340000000000005\n",
      "10 trial fin\n",
      "{'num_layer': 4, 'mid_units': 300.0, 'num_filter_0': 112.0, 'num_filter_1': 112.0, 'num_filter_2': 48.0, 'num_filter_3': 64.0, 'activation': 'ReLU', 'optimizer': 'MomentumSGD', 'weight_decay': 1.5857281082687515e-06, 'momentum_sgd_lr': 0.008321891507804836}\n",
      "0.0131\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import random\n",
    "import ipdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from optuna.integration.tensorboard import TensorBoardCallback\n",
    "import optuna\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "\n",
    "#set seeds\n",
    "def torch_fix_seed(seed=42):\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True\n",
    "\n",
    "torch_fix_seed()\n",
    "\n",
    "\n",
    "BATCHSIZE = 128\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCHSIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCHSIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = tuple(np.linspace(0, 9, 10, dtype=np.uint8))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#モデルの定義\n",
    "\n",
    "#入力画像の高さと幅，畳み込み層のカーネルサイズ\n",
    "in_height = 28\n",
    "in_width = 28\n",
    "kernel = 3\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, trial, num_layer, mid_units, num_filters):\n",
    "    super(Net, self).__init__()\n",
    "    self.activation = get_activation(trial)\n",
    "    #第1層\n",
    "    self.convs = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=num_filters[0], kernel_size=3)])\n",
    "    self.out_height = in_height - kernel +1\n",
    "    self.out_width = in_width - kernel +1\n",
    "    #第2層以降\n",
    "    for i in range(1, num_layer):\n",
    "      self.convs.append(nn.Conv2d(in_channels=num_filters[i-1], out_channels=num_filters[i], kernel_size=3))\n",
    "      self.out_height = self.out_height - kernel + 1\n",
    "      self.out_width = self.out_width - kernel +1\n",
    "    #pooling層\n",
    "    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "    self.out_height = int(self.out_height / 2)\n",
    "    self.out_width = int(self.out_width / 2)\n",
    "    #線形層\n",
    "    self.out_feature = self.out_height * self.out_width * num_filters[num_layer - 1]\n",
    "    self.fc1 = nn.Linear(in_features=self.out_feature, out_features=mid_units) \n",
    "    self.fc2 = nn.Linear(in_features=mid_units, out_features=10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    for i, l in enumerate(self.convs):\n",
    "      x = l(x)\n",
    "      x = self.activation(x)\n",
    "    x = self.pool(x)\n",
    "    x = x.view(-1, self.out_feature)\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    return 1 - correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def get_optimizer(trial, model):\n",
    "  optimizer_names = ['Adam', 'MomentumSGD', 'rmsprop']\n",
    "  optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n",
    "  \n",
    "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n",
    "  \n",
    "  if optimizer_name == optimizer_names[0]: \n",
    "    adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=adam_lr, weight_decay=weight_decay)\n",
    "  elif optimizer_name == optimizer_names[1]:\n",
    "    momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=momentum_sgd_lr, momentum=0.9, weight_decay=weight_decay)\n",
    "  else:\n",
    "    optimizer = optim.RMSprop(model.parameters())\n",
    "  \n",
    "  return optimizer\n",
    "\n",
    "def get_activation(trial):\n",
    "    activation_names = ['ReLU', 'ELU']\n",
    "    activation_name = trial.suggest_categorical('activation', activation_names)\n",
    "    \n",
    "    if activation_name == activation_names[0]:\n",
    "        activation = F.relu\n",
    "    else:\n",
    "        activation = F.elu\n",
    "    \n",
    "    return activation\n",
    "\n",
    "EPOCH = 10\n",
    "def objective(trial):\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  print(f'device == {device}')\n",
    "  \n",
    "  #畳み込み層の数\n",
    "  num_layer = trial.suggest_int('num_layer', 3, 7)\n",
    "  \n",
    "  #FC層のユニット数\n",
    "  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 500, 100))\n",
    "  \n",
    "  #各畳込み層のフィルタ数\n",
    "  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n",
    "  \n",
    "  model = Net(trial, num_layer, mid_units, num_filters).to(device)\n",
    "  optimizer = get_optimizer(trial, model)\n",
    "  \n",
    "  for step in range(EPOCH):\n",
    "    train(model, device, train_loader, optimizer)\n",
    "    error_rate = test(model, device, test_loader)\n",
    "    print(f'{step}fin | error rate {error_rate}')\n",
    "\n",
    "  print(f'{trial.number + 1} trial fin')\n",
    "  return error_rate\n",
    "\n",
    "\n",
    "TRIAL_SIZE = 10\n",
    "tensorboard_callback = TensorBoardCallback(f\"logs/MNIST/{datetime.datetime.now()}/Optuna/\", metric_name=\"error_rate\")\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=TRIAL_SIZE, callbacks=[tensorboard_callback])\n",
    "# ipdb.set_trace()\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Optuna_with_PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
