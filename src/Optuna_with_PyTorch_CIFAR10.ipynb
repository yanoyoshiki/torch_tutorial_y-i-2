{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 初めに\n","今回は課題指示書の「ハイパラメータチューニングに慣れる」という目的ベースで課題とは異なる順序で課題をまとめた.\n","\n","\n","具体的には各要素は守りつつハイパラメータ調整ライブラリoptunaに重点を置いたものとなっている．\n","\n","\n","このnotebookはCIFAR10を対象にしたCNN構築を一貫して行っている．\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1903,"status":"ok","timestamp":1688816942903,"user":{"displayName":"矢野嘉希","userId":"01023143812427193590"},"user_tz":-540},"id":"CElpKgnAnF9k","outputId":"6aad7f9a-57fc-40c5-d9ae-3813e00330b1"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-07-12 18:15:54.381637: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-07-12 18:15:54.407247: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-07-12 18:15:54.897908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["# NumPy、Matplotlib、PyTorchをインポートする\n","import datetime\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import ipdb\n","import random\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from optuna.integration.tensorboard import TensorBoardCallback\n","\n","\n","import optuna\n","optuna.logging.disable_default_handler()\n","\n","\n","#set seeds\n","def torch_fix_seed(seed=42):\n","    # Python random\n","    random.seed(seed)\n","    # Numpy\n","    np.random.seed(seed)\n","    # Pytorch\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.use_deterministic_algorithms = True\n","\n","\n","torch_fix_seed()\n","\n","\n","#入力画像の高さと幅，畳み込み層のカーネルサイズ\n","in_height = 32\n","in_width = 32\n","kernel = 5\n","BATCHSIZE = 4\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","train_loader = DataLoader(train_set, batch_size=BATCHSIZE, shuffle=True, num_workers=2)\n","\n","test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","test_loader = DataLoader(test_set, batch_size=BATCHSIZE, shuffle=False, num_workers=2)\n","\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1688816942904,"user":{"displayName":"矢野嘉希","userId":"01023143812427193590"},"user_tz":-540},"id":"iI8b6DEvnImr"},"outputs":[],"source":["class Net(nn.Module):\n","  def __init__(self, trial, num_layer, mid_units, num_filters):\n","    super(Net, self).__init__()\n","    self.activation = get_activation(trial)\n","    #第1層\n","    self.convs = nn.ModuleList([nn.Conv2d(in_channels=3, out_channels=num_filters[0], kernel_size=5)])\n","    self.out_height = in_height - kernel +1\n","    self.out_width = in_width - kernel +1\n","    #第2層以降\n","    for i in range(1, num_layer):\n","      self.convs.append(nn.Conv2d(in_channels=num_filters[i-1], out_channels=num_filters[i], kernel_size=5))\n","      self.out_height = self.out_height - kernel + 1\n","      self.out_width = self.out_width - kernel +1\n","    #pooling層\n","    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n","    self.out_height = int(self.out_height / 2)\n","    self.out_width = int(self.out_width / 2)\n","    #線形層\n","    self.out_feature = self.out_height * self.out_width * num_filters[num_layer - 1]\n","    self.fc1 = nn.Linear(in_features=self.out_feature, out_features=mid_units)\n","    self.fc2 = nn.Linear(in_features=mid_units, out_features=10)\n","\n","  def forward(self, x):\n","    for i, l in enumerate(self.convs):\n","      x = l(x)\n","      x = self.activation(x)\n","    x = self.pool(x)\n","    x = x.view(-1, self.out_feature)\n","    x = self.fc1(x)\n","    x = self.fc2(x)\n","    return F.log_softmax(x, dim=1)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1688817457827,"user":{"displayName":"矢野嘉希","userId":"01023143812427193590"},"user_tz":-540},"id":"CAa7nBc0nLPB"},"outputs":[],"source":["def train(model, device, train_loader, optimizer):\n","  model.train()\n","  loss_corect = 0\n","  for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()  \n","        loss_corect+=loss\n","  return loss_corect / len(train_loader)\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in test_loader:\n","            inputs, labels = data[0].to(device), data[1].to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return 1 - correct / len(test_loader.dataset)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":243,"status":"ok","timestamp":1688817459149,"user":{"displayName":"矢野嘉希","userId":"01023143812427193590"},"user_tz":-540},"id":"mNWtzhLFnNVz"},"outputs":[],"source":["def get_optimizer(trial, model):\n","  optimizer_names = ['Adam', 'MomentumSGD', 'rmsprop']\n","  optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n","\n","  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n","\n","  if optimizer_name == optimizer_names[0]:\n","    adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n","    optimizer = optim.Adam(model.parameters(), lr=adam_lr, weight_decay=weight_decay)\n","  elif optimizer_name == optimizer_names[1]:\n","    momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n","    optimizer = optim.SGD(model.parameters(), lr=momentum_sgd_lr, momentum=0.9, weight_decay=weight_decay)\n","  else:\n","    optimizer = optim.RMSprop(model.parameters())\n","\n","  return optimizer"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":411,"status":"ok","timestamp":1688817460910,"user":{"displayName":"矢野嘉希","userId":"01023143812427193590"},"user_tz":-540},"id":"dRoTVTSinQIX"},"outputs":[],"source":["def get_activation(trial):\n","    activation_names = ['ReLU', 'ELU']\n","    activation_name = trial.suggest_categorical('activation', activation_names)\n","\n","    if activation_name == activation_names[0]:\n","        activation = F.relu\n","    else:\n","        activation = F.elu\n","\n","    return activation\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1688817634261,"user":{"displayName":"矢野嘉希","userId":"01023143812427193590"},"user_tz":-540},"id":"06yJ1OOEnSIn"},"outputs":[],"source":["\n","def objective(trial):\n","  # writer = SummaryWriter(log_dir=f\"logs/CIFAR10/{datetime.datetime.now()}/learning/trial_{trial.number}/\")\n","  EPOCH = 20\n","  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","  #畳み込み層の数\n","  num_layer = trial.suggest_int('num_layer', 3, 7)\n","\n","  #FC層のユニット数\n","  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 300, 10))\n","\n","  #各畳込み層のフィルタ数\n","  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n","\n","  model = Net(trial, num_layer, mid_units, num_filters).to(device)\n","  optimizer = get_optimizer(trial, model)\n","\n","  for step in range(EPOCH):\n","    loss=train(model, device, train_loader, optimizer)\n","    error_rate = test(model, device, test_loader)\n","    # writer.add_scalar(\"loss\", loss, step)  \n","    # writer.add_scalar(\"accuracy\", error_rate, step)  \n","    print(f'{step}fin | error rate {error_rate}')\n","\n","  print(f'{trial.number} trial fin')\n","  return error_rate"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmDi93T2nU_n","outputId":"dc0fe2b0-b3e5-4359-9a89-e1aa9d05d6aa"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_1312681/738128449.py:2: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n","  tensorboard_callback = TensorBoardCallback(f\"logs/CIFAR10/{datetime.datetime.now()}/Optuna/\", metric_name=\"error_rate\")\n","/tmp/ipykernel_1312681/3479177853.py:10: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 300, 10))\n","/tmp/ipykernel_1312681/3479177853.py:13: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n","/tmp/ipykernel_1312681/3089434429.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n"]},{"name":"stdout","output_type":"stream","text":["0fin | error rate 0.9\n"]},{"name":"stderr","output_type":"stream","text":["Trial 0 failed with parameters: {'num_layer': 5, 'mid_units': 120.0, 'num_filter_0': 112.0, 'num_filter_1': 32.0, 'num_filter_2': 64.0, 'num_filter_3': 128.0, 'num_filter_4': 96.0, 'activation': 'ELU', 'optimizer': 'rmsprop', 'weight_decay': 8.336314537368577e-07} because of the following error: KeyboardInterrupt().\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/tmp/ipykernel_1312681/3479177853.py\", line 19, in objective\n","    loss=train(model, device, train_loader, optimizer)\n","  File \"/tmp/ipykernel_1312681/347795912.py\", line 9, in train\n","    loss.backward()\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/_tensor.py\", line 488, in backward\n","    torch.autograd.backward(\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 197, in backward\n","    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n","Trial 0 failed with value None.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m TensorBoardCallback(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogs/CIFAR10/\u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m}\u001b[39;00m\u001b[39m/Optuna/\u001b[39m\u001b[39m\"\u001b[39m, metric_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39merror_rate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study()\n\u001b[0;32m----> 4\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49mTRIAL_SIZE, callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback])\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(study\u001b[39m.\u001b[39mbest_params)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(study\u001b[39m.\u001b[39mbest_value)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     _optimize(\n\u001b[1;32m    444\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    445\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    449\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    453\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer \u001b[39m=\u001b[39m get_optimizer(trial, model)\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCH):\n\u001b[0;32m---> 19\u001b[0m   loss\u001b[39m=\u001b[39mtrain(model, device, train_loader, optimizer)\n\u001b[1;32m     20\u001b[0m   error_rate \u001b[39m=\u001b[39m test(model, device, test_loader)\n\u001b[1;32m     21\u001b[0m   \u001b[39m# writer.add_scalar(\"loss\", loss, step)  \u001b[39;00m\n\u001b[1;32m     22\u001b[0m   \u001b[39m# writer.add_scalar(\"accuracy\", error_rate, step)  \u001b[39;00m\n","Cell \u001b[0;32mIn[3], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m      8\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnll_loss(output, target)\n\u001b[0;32m----> 9\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     10\u001b[0m optimizer\u001b[39m.\u001b[39mstep()  \n\u001b[1;32m     11\u001b[0m loss_corect\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mloss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["TRIAL_SIZE = 50\n","tensorboard_callback = TensorBoardCallback(f\"logs/CIFAR10/{datetime.datetime.now()}/Optuna/\", metric_name=\"error_rate\")\n","study = optuna.create_study()\n","study.optimize(objective, n_trials=TRIAL_SIZE, callbacks=[tensorboard_callback])\n","\n","print(study.best_params)\n","print(study.best_value)\n","\n","best_params_result = study.best_params"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## まとめ\n","以上の実行中のハイパラメータは指定範囲の中から選ばれたものを採用しているだけのため, 精度があまり芳しくない."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 結果\n","ここから以上で設定したハイパラは以下のものが行った思考の中で最適であると判断された．"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 最適パラメータ結果との比較\n","精度としてハイパラメータ最適化を行ったネットワークは性能が高く，チューニングを行っていないネットワークに関しては非常に悪い結果となっていることがわかる．\n","\n","\n","このパラメータ指定を行う際にはこのディレクトリ内に存在する.py を実行することで特定パラメータにおける性能評価を実現できる．"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["このOptunaを用いたパラメータ探索に関しては ./Optuna_CIFAR10.py で実装を行ったそのため以下のコマンドを実行すると学習およびパラメータ探索が開始される．\n","上の行為は時間がかかるのでこちらも筆者が実行した結果をtesorboardで確認する．\n","\n","以下の写真からわかることは各パラーメータ値とそのパラメータ設定で推論を行った時の精度である．\n","\n","errorrateと他パラメータの関係として以下のことが挙げられる\n","\n","\n","- \n","- \n","- \n","\n","以上のことから_________________________ということが言える．\n","\n","Optunaには最適パラメータを保持する機能があり，その保持パラーメータとそのハイパラで組まれたネットワークのerror rateが出力できる．\n","\n","\n","この結果より発見されたパラメータは\n","\n","\n","ーーー\n","\n","\n","であり，そのネットワークでのerror rateはーーー\n","\n","\n","調整前よりも性能が上がっていることが確認できる．"]},{"cell_type":"markdown","metadata":{},"source":["## all code\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_86712/143914539.py:174: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n","  tensorboard_callback = TensorBoardCallback(f\"logs/CIFAR10/{datetime.datetime.now()}/Optuna/\", metric_name=\"error_rate\")\n","/tmp/ipykernel_86712/143914539.py:155: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 300, 10))\n","/tmp/ipykernel_86712/143914539.py:158: FutureWarning: suggest_discrete_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., step=...) instead.\n","  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n","/tmp/ipykernel_86712/143914539.py:122: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n","/tmp/ipykernel_86712/143914539.py:125: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n"]},{"name":"stdout","output_type":"stream","text":["0fin | error rate 0.5188999999999999\n","1fin | error rate 0.4104\n","2fin | error rate 0.37570000000000003\n","3fin | error rate 0.3316\n","4fin | error rate 0.33089999999999997\n","5fin | error rate 0.3075\n","6fin | error rate 0.33240000000000003\n","7fin | error rate 0.31989999999999996\n","8fin | error rate 0.3173\n","9fin | error rate 0.3183\n","0 trial fin\n"]},{"name":"stderr","output_type":"stream","text":["2023-07-11 19:57:48.118020: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-07-11 19:57:48.118547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-07-11 19:57:48.118614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-07-11 19:57:48.119318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-07-11 19:57:48.119396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-07-11 19:57:48.119454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-07-11 19:57:48.119584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-07-11 19:57:48.119651: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-07-11 19:57:48.119711: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-07-11 19:57:48.119764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1268 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"]},{"name":"stdout","output_type":"stream","text":["0fin | error rate 0.9\n","1fin | error rate 0.9\n","2fin | error rate 0.9\n","3fin | error rate 0.9\n","4fin | error rate 0.9\n","5fin | error rate 0.9\n","6fin | error rate 0.9\n","7fin | error rate 0.9\n","8fin | error rate 0.9\n","9fin | error rate 0.9\n","1 trial fin\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_86712/143914539.py:128: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n"]},{"name":"stdout","output_type":"stream","text":["0fin | error rate 0.8513999999999999\n","1fin | error rate 0.8061\n","2fin | error rate 0.7518\n","3fin | error rate 0.7156\n","4fin | error rate 0.6796\n","5fin | error rate 0.6667000000000001\n","6fin | error rate 0.6517999999999999\n","7fin | error rate 0.6427\n","8fin | error rate 0.627\n","9fin | error rate 0.6041000000000001\n","2 trial fin\n","0fin | error rate 0.8359\n","1fin | error rate 0.7533\n","2fin | error rate 0.7089\n","3fin | error rate 0.679\n","4fin | error rate 0.655\n","5fin | error rate 0.6426000000000001\n","6fin | error rate 0.6304000000000001\n","7fin | error rate 0.6201\n","8fin | error rate 0.6109\n","9fin | error rate 0.6066\n","3 trial fin\n","0fin | error rate 0.9\n","1fin | error rate 0.9\n","2fin | error rate 0.8543000000000001\n","3fin | error rate 0.837\n","4fin | error rate 0.7229\n","5fin | error rate 0.6458999999999999\n","6fin | error rate 0.5924\n","7fin | error rate 0.5397000000000001\n","8fin | error rate 0.5122\n","9fin | error rate 0.4737\n","4 trial fin\n","0fin | error rate 0.9\n","1fin | error rate 0.9\n","2fin | error rate 0.9\n","3fin | error rate 0.9\n","4fin | error rate 0.9\n","5fin | error rate 0.9\n","6fin | error rate 0.9\n","7fin | error rate 0.9\n","8fin | error rate 0.9\n","9fin | error rate 0.9\n","5 trial fin\n","0fin | error rate 0.9\n","1fin | error rate 0.9\n","2fin | error rate 0.9\n","3fin | error rate 0.9\n","4fin | error rate 0.9\n","5fin | error rate 0.9\n","6fin | error rate 0.9\n","7fin | error rate 0.9\n","8fin | error rate 0.9\n","9fin | error rate 0.9\n","6 trial fin\n","0fin | error rate 0.9\n","1fin | error rate 0.9\n","2fin | error rate 0.9\n","3fin | error rate 0.9\n","4fin | error rate 0.9\n","5fin | error rate 0.9\n","6fin | error rate 0.9\n","7fin | error rate 0.9\n","8fin | error rate 0.9\n","9fin | error rate 0.9\n","7 trial fin\n","0fin | error rate 0.9\n","1fin | error rate 0.9\n","2fin | error rate 0.9\n","3fin | error rate 0.9\n","4fin | error rate 0.9\n","5fin | error rate 0.9\n","6fin | error rate 0.9\n","7fin | error rate 0.9\n","8fin | error rate 0.9\n","9fin | error rate 0.9\n","8 trial fin\n","0fin | error rate 0.9\n","1fin | error rate 0.9\n","2fin | error rate 0.9\n","3fin | error rate 0.9\n","4fin | error rate 0.9\n","5fin | error rate 0.9\n","6fin | error rate 0.9\n","7fin | error rate 0.9\n","8fin | error rate 0.9\n","9fin | error rate 0.9\n","9 trial fin\n","{'num_layer': 5, 'mid_units': 150.0, 'num_filter_0': 32.0, 'num_filter_1': 48.0, 'num_filter_2': 16.0, 'num_filter_3': 96.0, 'num_filter_4': 48.0, 'activation': 'ELU', 'optimizer': 'Adam', 'weight_decay': 1.7471409665748117e-06, 'adam_lr': 0.0001629992471829847}\n","0.3183\n"]}],"source":["# NumPy、Matplotlib、PyTorchをインポートする\n","import datetime\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import ipdb\n","import random\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from optuna.integration.tensorboard import TensorBoardCallback\n","\n","\n","import optuna\n","optuna.logging.disable_default_handler()\n","\n","\n","#set seeds\n","def torch_fix_seed(seed=42):\n","    # Python random\n","    random.seed(seed)\n","    # Numpy\n","    np.random.seed(seed)\n","    # Pytorch\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.use_deterministic_algorithms = True\n","\n","\n","torch_fix_seed()\n","\n","\n","#入力画像の高さと幅，畳み込み層のカーネルサイズ\n","in_height = 32\n","in_width = 32\n","kernel = 5\n","BATCHSIZE = 4\n","\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","train_loader = DataLoader(train_set, batch_size=BATCHSIZE, shuffle=True, num_workers=2)\n","\n","test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","test_loader = DataLoader(test_set, batch_size=BATCHSIZE, shuffle=False, num_workers=2)\n","\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","\n","\n","class Net(nn.Module):\n","  def __init__(self, trial, num_layer, mid_units, num_filters):\n","    super(Net, self).__init__()\n","    self.activation = get_activation(trial)\n","    #第1層\n","    self.convs = nn.ModuleList([nn.Conv2d(in_channels=3, out_channels=num_filters[0], kernel_size=5)])\n","    self.out_height = in_height - kernel +1\n","    self.out_width = in_width - kernel +1\n","    #第2層以降\n","    for i in range(1, num_layer):\n","      self.convs.append(nn.Conv2d(in_channels=num_filters[i-1], out_channels=num_filters[i], kernel_size=5))\n","      self.out_height = self.out_height - kernel + 1\n","      self.out_width = self.out_width - kernel +1\n","    #pooling層\n","    self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n","    self.out_height = int(self.out_height / 2)\n","    self.out_width = int(self.out_width / 2)\n","    #線形層\n","    self.out_feature = self.out_height * self.out_width * num_filters[num_layer - 1]\n","    self.fc1 = nn.Linear(in_features=self.out_feature, out_features=mid_units)\n","    self.fc2 = nn.Linear(in_features=mid_units, out_features=10)\n","\n","  def forward(self, x):\n","    for i, l in enumerate(self.convs):\n","      x = l(x)\n","      x = self.activation(x)\n","    x = self.pool(x)\n","    x = x.view(-1, self.out_feature)\n","    x = self.fc1(x)\n","    x = self.fc2(x)\n","    return F.log_softmax(x, dim=1)\n","\n","def train(model, device, train_loader, optimizer):\n","  model.train()\n","  loss_corect = 0\n","  for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()  \n","        loss_corect+=loss\n","  return loss_corect / len(train_loader)\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in test_loader:\n","            inputs, labels = data[0].to(device), data[1].to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return 1 - correct / len(test_loader.dataset)\n","\n","def get_optimizer(trial, model):\n","  optimizer_names = ['Adam', 'MomentumSGD', 'rmsprop']\n","  optimizer_name = trial.suggest_categorical('optimizer', optimizer_names)\n","\n","  weight_decay = trial.suggest_loguniform('weight_decay', 1e-10, 1e-3)\n","\n","  if optimizer_name == optimizer_names[0]:\n","    adam_lr = trial.suggest_loguniform('adam_lr', 1e-5, 1e-1)\n","    optimizer = optim.Adam(model.parameters(), lr=adam_lr, weight_decay=weight_decay)\n","  elif optimizer_name == optimizer_names[1]:\n","    momentum_sgd_lr = trial.suggest_loguniform('momentum_sgd_lr', 1e-5, 1e-1)\n","    optimizer = optim.SGD(model.parameters(), lr=momentum_sgd_lr, momentum=0.9, weight_decay=weight_decay)\n","  else:\n","    optimizer = optim.RMSprop(model.parameters())\n","\n","  return optimizer\n","\n","def get_activation(trial):\n","    activation_names = ['ReLU', 'ELU']\n","    activation_name = trial.suggest_categorical('activation', activation_names)\n","\n","    if activation_name == activation_names[0]:\n","        activation = F.relu\n","    else:\n","        activation = F.elu\n","\n","    return activation\n","\n","def objective(trial):\n","  # writer = SummaryWriter(log_dir=f\"logs/CIFAR10/{datetime.datetime.now()}/learning/trial_{trial.number}/\")\n","  EPOCH = 10\n","  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","  #畳み込み層の数\n","  num_layer = trial.suggest_int('num_layer', 3, 7)\n","\n","  #FC層のユニット数\n","  mid_units = int(trial.suggest_discrete_uniform(\"mid_units\", 100, 300, 10))\n","\n","  #各畳込み層のフィルタ数\n","  num_filters = [int(trial.suggest_discrete_uniform(\"num_filter_\"+str(i), 16, 128, 16)) for i in range(num_layer)]\n","\n","  model = Net(trial, num_layer, mid_units, num_filters).to(device)\n","  optimizer = get_optimizer(trial, model)\n","\n","  for step in range(EPOCH):\n","    loss=train(model, device, train_loader, optimizer)\n","    error_rate = test(model, device, test_loader)\n","    # writer.add_scalar(\"loss\", loss, step)  \n","    # writer.add_scalar(\"accuracy\", error_rate, step)  \n","    print(f'{step}fin | error rate {error_rate}')\n","\n","  print(f'{trial.number} trial fin')\n","  return error_rate\n","\n","TRIAL_SIZE = 10\n","tensorboard_callback = TensorBoardCallback(f\"logs/CIFAR10/{datetime.datetime.now()}/Optuna/\", metric_name=\"error_rate\")\n","study = optuna.create_study()\n","study.optimize(objective, n_trials=TRIAL_SIZE, callbacks=[tensorboard_callback])\n","\n","print(study.best_params)\n","print(study.best_value)\n","\n","best_params_result = study.best_params\n","\n","#output\n","#{'num_layer': 4, 'mid_units': 140.0, 'num_filter_0': 128.0, 'num_filter_1': 112.0, 'num_filter_2': 112.0, 'num_filter_3': 112.0, 'activation': 'ReLU', 'optimizer': 'MomentumSGD', 'weight_decay': 5.2182135446336915e-08, 'momentum_sgd_lr': 0.0004955865902351846}\n","#0.2519\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
